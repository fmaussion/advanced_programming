{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c82e58-0d73-4dc5-b938-7a96989eebd0",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9295250-c6de-45ad-8859-95a3cd6c79e7",
   "metadata": {},
   "source": [
    "## Week 06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbd17f-fa17-4eaa-a992-577634f85722",
   "metadata": {},
   "source": [
    "*\"Due date\": 09.05.2022* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3dab53-3a9f-46e2-9277-88104326bd26",
   "metadata": {},
   "source": [
    "### Exercise 01: xarray sel points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e3080-c1de-41de-9524-5a874af41866",
   "metadata": {},
   "source": [
    "Data:\n",
    "- https://cluster.klima.uni-bremen.de/~fmaussion/teaching/advpro/Copernicus_DSM_10_N46_00_E010_00_DEM.tif\n",
    "- https://cluster.klima.uni-bremen.de/~fmaussion/teaching/advpro/HEF_RGI.zip\n",
    "\n",
    "Let me open this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f872c-658c-4d65-9247-174dcc84d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rioxr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9377d0a-4f6e-4c23-89dd-326f7bff8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = rioxr.open_rasterio('Copernicus_DSM_10_N46_00_E010_00_DEM.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c790e2-f7d0-4334-9135-d4a176cdffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('zip://HEF_RGI.zip!/HEF_RGI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bea9b-a349-43be-beda-01a60d789767",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots();\n",
    "da.plot(ax=ax);\n",
    "gdf.plot(ax=ax, facecolor='C3', edgecolor='C3');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf58a96-05b0-4999-8001-d179b401ac3c",
   "metadata": {},
   "source": [
    "Good! Now:\n",
    "- extract the lons and lats coordinates of the glacier outline (this is a geopandas + shapely question)\n",
    "- use [xarray interpolation](https://docs.xarray.dev/en/stable/user-guide/interpolation.html) to get the elevation of each vertice along the outlines\n",
    "- make a plot more or less [looking like this](https://github.com/fmaussion/advanced_programming/blob/master/book/03_advanced_xarray/xarray_interp.png).\n",
    "\n",
    "The whole exercise is 4 lines of code. It's all about reading the docs ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d024dee5-d8b9-4658-906c-576946b2d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698968f0-0c06-4ed7-bd8f-34c2c56dfde7",
   "metadata": {},
   "source": [
    "### Exercise 02: medium data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694b729-5a12-4fbf-a5ab-87f2036b2f6f",
   "metadata": {},
   "source": [
    "Please read the [dask + xarray documentation](https://docs.xarray.dev/en/latest/user-guide/dask.html) page first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e53af-b44f-4e46-995a-2a00871c70e3",
   "metadata": {},
   "source": [
    "I have downloaded ERA5 hourly precipitation data for you. You will find the files here: https://cluster.klima.uni-bremen.de/~fmaussion/teaching/climate/dask_exps/HiRes_Hourly_Surf\n",
    "\n",
    "I'm still downloading them, but the year 2021 is complete. **Your task is to compute the daily cycle (i.e. hourly average) over the entire year 2021.** (shape: `(24, nlat, nlon)`).\n",
    "\n",
    "You can do so by various means, but as a first step I recommend to:\n",
    "- open all 12 monthly files individually in a for loop\n",
    "- use dask to chunk the files before computing the daily cycle (not strictly necessary but you can try with and without it)\n",
    "- save the output in an intermediate netcdf file\n",
    "- open the intermediate netcdf files to average them (ideally weighting by month length)\n",
    "\n",
    "**If you are adventurous,** try to do it without for loop, with `open_mfdataset`. Since Monday I've tried quite a few things myself and discovered one of the main problems I was facing with `open_mfdataset`: one needs to specify the chunks *at opening* (i.e. `open_mfdataset('', chunks=...)` and not after (as I tried to do in class). I even [opened a PR](https://github.com/pydata/xarray/pull/6569) to improve the xarray docs in this respect. With this I *almost* managed to compute the daily cycle but it is still not working as efficiently as I'd like it to. Maybe it'll work better for you?\n",
    "\n",
    "\n",
    "**Bonus**: make a pretty gif out of it:\n",
    "\n",
    "![](example_2021.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94865f6-ed29-4951-8596-99d647aea3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
