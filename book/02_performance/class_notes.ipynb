{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a44b787-7a30-4c7b-850e-cade398be361",
   "metadata": {},
   "source": [
    "# Advanced programming: performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e29c3-2b77-4c66-914d-fa30caab5b46",
   "metadata": {},
   "source": [
    "https://hackmd.io/@fmaussion/rJlfAkJm5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ba05c-197e-42ac-b749-af76b1347112",
   "metadata": {},
   "source": [
    "## The rules of optimization\n",
    "\n",
    "\n",
    "1. **Don't do it.**\n",
    "2. **(For experts only) Don't do it yet.**\n",
    "\n",
    "Inspired from famous internet programmer knowledge.\n",
    "\n",
    "### Rules of thumb\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/is_it_worth_the_time_2x.png\" alt=\"xkcd\" width=\"400\"/>\n",
    "\n",
    "### If you really really want to do it anyway\n",
    "\n",
    "1. **Write tests**\n",
    "2. **Profile before optimizing**\n",
    "\n",
    "Writing tests is important to keep the code running and making sure that it works the same way after optimizing. At the very least, keep a copy of the non-optimized code and test your optimized code against it.\n",
    "\n",
    "Profiling helps to focus on what really matters. You might find the results of profiling very surprising!\n",
    "\n",
    "## Some optimisation stories from the class\n",
    "\n",
    "- vectorization instead of for-loops\n",
    "- from fortran to c (or vice versa): change the order of accessing rows and columns\n",
    "- conversion between xarray/numpy arrays etc. is expensive - avoid it if you need performance\n",
    "- writing functions instead of hard-coding every single step multiple times\n",
    "- opening the same file every time in a for-loop instead of doing it once before starting the for-loop\n",
    "- think of writing your own functions for routines you are using a lot instead of potentially slow package functions (e.g. `np.average`). See examples below.\n",
    "\n",
    "## Profiling code\n",
    "\n",
    "- default: https://docs.python.org/3/library/profile.html\n",
    "- with graphics: https://github.com/benfred/py-spy\n",
    "\n",
    "## Optimisation examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388406b7-dddd-42c0-92d3-907a879229d6",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "Always follow the further rules of scientific code optimisation in order:\n",
    "\n",
    "1. Don't do it.\n",
    "2. Don't do it (yet)\n",
    "3. Test before doing it\n",
    "4. Profile before doing it\n",
    "5. Check vectorization (removing `for` loops)\n",
    "6. Remove pandas / xarray overlay\n",
    "7. Optimize numpy code\n",
    "8. Check numba or PyPy \n",
    "8. Use multiprocessing\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bfaba-cefc-4050-b9a6-baa637d8f064",
   "metadata": {},
   "source": [
    "### Vectorization is awesome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb10c7-3387-4fd4-a7d7-bcb48fe0b92f",
   "metadata": {},
   "source": [
    "This is ALWAYS what you should check first: can you replace a for loop with numpy only arithmetics?\n",
    "\n",
    "Example salem and MetPy's `interp_1d` function (useful for interpolating model levels):\n",
    "- [salem](https://github.com/fmaussion/salem/blob/0ae5885e4f466fc333a14544df851501f11102fd/salem/wrftools.py#L496-L551) uses naive interpolation but relies on multiprocessing to get speed-up\n",
    "- [MetPy](https://github.com/Unidata/MetPy/blob/8b01e1fd22304ffcd5e933cfa901a229ab8fba3f/src/metpy/interpolate/one_dimension.py#L53-L173) uses clever vectorization and is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e1f26-7791-4b66-bf0e-e8f1c99cbe0c",
   "metadata": {},
   "source": [
    "### Back to basics: xarray -> numpy -> own functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83206197-a6bc-43da-92f9-30818e9f1b76",
   "metadata": {},
   "source": [
    "Because of the \"generalization overhead\" (certain numpy and xarray functions are slow because they are meant to be general and do a lot of input checks.\n",
    "\n",
    "If you know what your input looks like and have control over it, you can speed-up operations quite a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2be34c-882c-44bd-bce0-dca508923125",
   "metadata": {},
   "source": [
    "#### xarray and pandas are slow on arithmetics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcff46cc-3bd3-463b-bf71-ecfddc52e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "da = xr.DataArray(np.random.uniform(size=(240, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b2307d-9765-44bf-8046-70d5983612c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.8 µs ± 1.61 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit da**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c39e1d2-fa5b-4766-abf3-ba4d500a3cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 µs ± 760 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit da.data**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4c062-7d6c-446f-a41c-446ed6c97e0a",
   "metadata": {},
   "source": [
    "*Question to class: why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e51594-ff5c-4a6b-9047-4b64b7e9fd79",
   "metadata": {},
   "source": [
    "#### numpy's general functions are sometimes slower than the direct arithmetic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54176cc3-df5a-41f1-8201-d8bf6e7b5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.arange(1, 1000)\n",
    "w = d + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76236bd-e36d-4a3b-9e50-de0417db2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 µs ± 1.31 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.average(d, weights=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eadda376-06a2-4f62-88fa-35dfde74a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_avg(d, wgt):\n",
    "    return np.multiply(d, wgt).sum() / wgt.sum()\n",
    "\n",
    "np.testing.assert_allclose(np.average(d, weights=w), my_avg(d, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31351cd3-ee16-42ef-8d1e-84c880b207df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.21 µs ± 197 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_avg(d, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25e4ba-e54a-4b07-b7c8-12dc3732ac3d",
   "metadata": {},
   "source": [
    "*Question to class: why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f40b00-f28f-48c9-9b9f-6800e7f281fe",
   "metadata": {},
   "source": [
    "See also (similar story): https://github.com/numpy/numpy/issues/14281"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8e7cb-fa7d-4bdb-ab52-4084f2110210",
   "metadata": {},
   "source": [
    "**As for ALL cases of optimisation: please be aware of the risks! Make a careful gain / costs analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef29f32-490f-4f85-b3d4-89fddca09292",
   "metadata": {},
   "source": [
    "#### Array creation is costly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efdae04-da81-4408-b571-7c6d606f9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 100\n",
    "nx = 200\n",
    "surface_h = np.linspace(3000, 1000, nx)\n",
    "\n",
    "\n",
    "def grad_np(surface_h, dx):\n",
    "    gradient = np.gradient(surface_h, dx)\n",
    "    gradient[[-1, 0]] = 0\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def my_grad(surface_h, dx):\n",
    "    gradient = np.zeros(surface_h.shape)\n",
    "    gradient[1:nx-1] = (surface_h[2:] - surface_h[:nx-2])/(2*dx)\n",
    "    gradient[[-1, 0]] = 0\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def my_other_grad(surface_h, dx):\n",
    "    internal_grad = (surface_h[2:] - surface_h[:nx-2])/(2*dx)\n",
    "    return np.concatenate([[0], internal_grad, [0]])\n",
    "\n",
    "\n",
    "gradient = np.zeros(surface_h.shape)\n",
    "\n",
    "\n",
    "def my_super_grad(surface_h, dx):\n",
    "    gradient[1:nx-1] = (surface_h[2:] - surface_h[:nx-2])/(2*dx)\n",
    "    gradient[[-1, 0]] = 0\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def my_super_super_grad(surface_h, dx):\n",
    "    gradient[1:nx-1] = (surface_h[2:] - surface_h[:nx-2])/(2*dx)\n",
    "    gradient[-1] = 0\n",
    "    gradient[0] = 0\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901c9ba9-5e1a-4f2c-9c7a-685ef4cc8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(grad_np(surface_h, dx), my_grad(surface_h, dx))\n",
    "np.testing.assert_allclose(grad_np(surface_h, dx), my_other_grad(surface_h, dx))\n",
    "np.testing.assert_allclose(grad_np(surface_h, dx), my_super_grad(surface_h, dx))\n",
    "np.testing.assert_allclose(grad_np(surface_h, dx), my_super_super_grad(surface_h, dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32740523-56de-4097-b17f-d7843e5c2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.3 µs ± 1.78 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit grad_np(surface_h, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4916cc-9c5b-4df9-95c6-8ba3e5e973d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.54 µs ± 305 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_other_grad(surface_h, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64337e6f-ffa2-456c-b4d6-8bf4ade3ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 µs ± 176 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_grad(surface_h, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "169e2cb8-8ea7-4672-9d49-c3296a7457ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32 µs ± 218 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_super_grad(surface_h, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b41cb87-cfc6-4889-a8ca-61d9c2cdfb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02 µs ± 53.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_super_super_grad(surface_h, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2d2f2-1c90-40a4-bb4b-c1c58729f9b8",
   "metadata": {},
   "source": [
    "#### But numpy is already super clever "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c762382-333c-4880-ad7d-95d744b99756",
   "metadata": {},
   "source": [
    "The following codes do the same. It is tempting to think that the second or third code are faster (because they use in-place operations), but it turns out that they are all exactly the same speed (within errors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a7aad53-18c9-49c6-94b6-84724f74ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_calc(surface_h):\n",
    "    out = surface_h + 1\n",
    "    out = surface_h * out\n",
    "    out = out - 100\n",
    "    out = out**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89b10f9f-cf97-4a4b-99aa-4bbdfcfcbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_useful_optim(surface_h):\n",
    "    return (surface_h * (surface_h + 1) - 100)**2\n",
    "\n",
    "np.testing.assert_allclose(some_calc(surface_h), not_useful_optim(surface_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "493babab-ca6d-4683-b616-6ee41b90f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def also_not_useful_optim(surface_h):\n",
    "    out = surface_h + 1\n",
    "    out *= surface_h\n",
    "    out -= 100\n",
    "    return out**2\n",
    "\n",
    "np.testing.assert_allclose(some_calc(surface_h), also_not_useful_optim(surface_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce0305ce-8277-4bcb-be01-fc8e5689a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.68 µs ± 251 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit some_calc(surface_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1662adbd-2dee-456e-b00c-ef9d03917c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 µs ± 157 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit not_useful_optim(surface_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b88a6a4-dd20-4cfa-a6b0-1c1046be05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98 µs ± 285 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit also_not_useful_optim(surface_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5f565-3812-4b37-b729-28f6731798f2",
   "metadata": {},
   "source": [
    "This is because python + numpy already knows how to compile this code to be optimized, i.e. it recognizes where the culprits are and solves them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b402e4-c4f0-41a4-9c39-7de05fc0c81b",
   "metadata": {},
   "source": [
    "### Just in time compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2d5e0-55c1-4a80-bc8b-dd5dabcfdef0",
   "metadata": {},
   "source": [
    "For pure numpy code with unavoidable loops (typical for numerical models with a time stepping for example), [numba](https://numba.pydata.org) is probably the best shot you have at considerably speeding up your code. We'll make an example in class.\n",
    "\n",
    "Numba is extensively used in some applications, e.g. for [cosipy](https://github.com/cryotools/cosipy). It has some drawbacks though (we discuss in class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76735091-2781-4dc7-aa71-418f124a8069",
   "metadata": {},
   "source": [
    "For some applications, [pypy](https://www.pypy.org) might be worth a shot but it requires using another python interpreter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
